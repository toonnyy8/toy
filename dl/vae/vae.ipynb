{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoXsY2Sq7y1T",
        "cellView": "form"
      },
      "source": [
        "train_gan = True #@param {type:\"boolean\"}\n",
        "download_state = True #@param {type:\"boolean\"}\n",
        "load_state = \"False\"  #@param [\"False\", \"From URL\", \"Upload\"]\n",
        "load_state_url = 'https://github.com/toonnyy8/toy/raw/main/dl/vae/vae.pt' #@param {type:\"string\"}\n",
        "\n",
        "if load_state == \"From URL\":\n",
        "    !wget {load_state_url}\n",
        "    \n",
        "elif load_state == \"Upload\":\n",
        "    from google.colab import files\n",
        "\n",
        "    uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lBGgyZxgjCm",
        "outputId": "d7ca94b8-c508-44bd-849d-c0963417f43d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWzv7eboan7V",
        "outputId": "cfe6b8ba-c70c-4c7e-cc21-7cd764c30d19"
      },
      "source": [
        "!pip install einops"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3kUpLlsZji"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch import optim\n",
        "\n",
        "from einops import rearrange, repeat\n",
        "import math\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import gc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brXruqS5s8Xu",
        "outputId": "03c0d8d9-6477-4d92-f490-480ddecf754a"
      },
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('GPU State:', device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU State: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgrWCfn-_M1R"
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, k_size=3):\n",
        "        super().__init__()\n",
        "        self.shortcut = nn.Identity() if in_dim == out_dim else nn.Conv2d(in_dim, out_dim, 1)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "                nn.GroupNorm(1, in_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Conv2d(in_dim, max(in_dim, out_dim)*2, k_size, padding=k_size//2),\n",
        "                nn.GroupNorm(1, max(in_dim, out_dim)*2),\n",
        "                nn.GELU(),\n",
        "                nn.Conv2d(max(in_dim, out_dim)*2, out_dim, k_size, padding=k_size//2),\n",
        "        )\n",
        "  \n",
        "    def forward(self, x):\n",
        "        return self.shortcut(x) + self.net(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSv7KQH6SKGZ"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dims, latent_dim):\n",
        "        super().__init__()\n",
        "        creat_nn = lambda in_dim, dim: nn.Sequential(\n",
        "                ResBlock(in_dim, dim, 3),\n",
        "                nn.AvgPool2d(2,2),\n",
        "            )\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            *[creat_nn(dims[i], dim) for i, dim in enumerate(dims[1:])],\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(dims[-1], latent_dim*2, 1,),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "  \n",
        "    def forward(self, x):\n",
        "        mu, logvar = torch.chunk(self.net(x), 2, 1)\n",
        "        return self.reparameterize(mu, logvar), mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        esp = torch.randn(*mu.size())\n",
        "        z = mu + std * esp\n",
        "        return z"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F_s2pYJmuE8"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, cond_num, latent_dim, pos_dim, dims, out_dim, scale):\n",
        "        super().__init__()\n",
        "        self.B = nn.Parameter(torch.randn(2, pos_dim, device=device)*scale, requires_grad=False)\n",
        "        self.cond_vecs = nn.Parameter(torch.randn(cond_num, 2, pos_dim, device=device)*scale, requires_grad=False)# torch.eye(cond_num, device=device)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(pos_dim*4+latent_dim, dims[0], 1),\n",
        "            *[ResBlock(dims[i], dim, 1) for i, dim in enumerate(dims[1:])],\n",
        "            nn.GroupNorm(1, dims[-1]),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dims[-1], out_dim, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "  \n",
        "    def forward(self, conds, latent_vecs, H, W):\n",
        "        coords_x = np.linspace(0, 1, W,)\n",
        "        coords_y = np.linspace(0, 1, H,)\n",
        "        coords = np.stack(np.meshgrid(coords_x, coords_y), 0) # (C, H, W)\n",
        "        coords = torch.tensor(coords, dtype=torch.float32, device=device)\n",
        "\n",
        "        pos_emb = repeat(torch.einsum('chw,cd->dhw', coords, self.B), 'd h w -> b d h w', b=len(conds))\n",
        "        cond_pos_emb = torch.einsum('chw,bcd->bdhw', coords, self.cond_vecs[conds])\n",
        "        u = 2*math.pi*torch.cat([pos_emb, cond_pos_emb], 1)\n",
        "\n",
        "        v = repeat(latent_vecs, 'b d -> b d h w', h=H, w=W)\n",
        "        z = torch.cat([torch.cos(u), torch.sin(u), v], 1)\n",
        "\n",
        "        out = self.net(z)\n",
        "        return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paluSPiDUHgm"
      },
      "source": [
        "def loss_fn(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 -  logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_I1YJUf7p7f"
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 128\n",
        "latent_dim = 16\n",
        "cond_num = 10"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IZAsbK0107a"
      },
      "source": [
        "enc_net = Encoder([3, 32, 64, 128], latent_dim).to(device)\n",
        "dec_net = Decoder(cond_num, latent_dim, 128, [64, 64, 64], 3, 2).to(device)\n",
        "opt = optim.Adamax(params=[*enc_net.parameters(), *dec_net.parameters()])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LJm7u9K9AVF"
      },
      "source": [
        "if not (load_state == 'False'):\n",
        "    checkpoint = torch.load(\"./vae.pt\", map_location=device)\n",
        "\n",
        "    enc_net.load_state_dict(checkpoint['enc_net'])\n",
        "    dec_net.load_state_dict(checkpoint['dec_net'])\n",
        "    opt.load_state_dict(checkpoint['opt'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jd7k99G8EQi",
        "outputId": "252860c5-d57e-47dc-a6be-191c11354cf0"
      },
      "source": [
        "if train_gan:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),            \n",
        "    ])\n",
        "    trainSet = CIFAR10(root='CIFAR10', download=True, train=True, transform=transform)\n",
        "    trainLoader = DataLoader(trainSet, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "pMlBKgq986Wz",
        "outputId": "ccc32408-5700-4f1a-e1c5-943af764c90b"
      },
      "source": [
        "if train_gan:\n",
        "    for epoch in range(epochs):\n",
        "        for (imgs,labels) in tqdm(trainLoader):\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            _bz = labels.shape[0]\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            latent_vecs, mu, logvar = enc_net(imgs)\n",
        "            recon_x = dec_net(labels, latent_vecs, H=32, W=32)\n",
        "\n",
        "            loss = loss_fn(recon_x, imgs, mu, logvar)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "            \n",
        "        with torch.no_grad():\n",
        "            labels = torch.arange(0, 10, device=device)\n",
        "            latent_vecs = torch.randn(10, latent_dim, device=device)\n",
        "\n",
        "            dec_out = dec_net(labels, latent_vecs, H=32, W=32)\n",
        "\n",
        "            fig , ax = plt.subplots()\n",
        "            for i in range(1, 11):\n",
        "                plt.subplot(2, 5, i)\n",
        "                plt.imshow(rearrange(dec_out[i-1], 'c h w -> h w c').cpu().data)\n",
        "            plt.show()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "  1%|          | 3/391 [00:14<31:38,  4.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ff5a396ef50b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H94FqKX1eR6U"
      },
      "source": [
        "if download_state:\n",
        "    torch.save({\n",
        "        \"enc_net\":enc_net.state_dict(),\n",
        "        \"dec_net\":dec_net.state_dict(),\n",
        "        \"opt\":opt.state_dict(),\n",
        "    }, './vae.pt')\n",
        "\n",
        "    from google.colab import files\n",
        "\n",
        "    files.download('./vae.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR7f1XwS6VGy",
        "cellView": "form"
      },
      "source": [
        "#@title 生成圖片\n",
        "%matplotlib inline\n",
        "from ipywidgets import interactive, widgets\n",
        "\n",
        "gen_class = 0  #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "gen_size = 28  #@param {type:\"slider\", min:16, max:128, step:1}\n",
        "\n",
        "g_net.eval()\n",
        "\n",
        "def f(**kwargs):\n",
        "    latent_vec = torch.tensor([[kwargs['dim {}'.format(i)] for i in range(latent_dim)]], device=device)\n",
        "    with torch.no_grad():\n",
        "        g_out = dec_net(torch.tensor([int(gen_class)], device=device), latent_vec, H=int(gen_size), W=int(gen_size))\n",
        "    \n",
        "    plt.figure(2, figsize=(20,6))\n",
        "    plt.imshow(rearrange(g_out[0], 'c h w -> h w c').cpu().data)\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "    \n",
        "\n",
        "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
        "    value=v,\n",
        "    min=mi,\n",
        "    max=ma,\n",
        "    step=.01,\n",
        ")\n",
        "names = [['dim {}'.format(i), [0., -5., 5]] for i in range(latent_dim)]\n",
        "\n",
        "interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
        "output = interactive_plot.children[-1]\n",
        "output.layout.height = '350px'\n",
        "interactive_plot"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}